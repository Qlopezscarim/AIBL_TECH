#include <stdio.h>
#include <stdlib.h>
#include <stdint.h>
#include <string.h>
#include <unistd.h>
#include <fcntl.h>
#include <sys/ioctl.h>
#include <linux/videodev2.h>
#include <sys/mman.h>
#include <algorithm>
#include <vector>
#include "net.h"

#define CAM_W 160
#define CAM_H 120
#define FB_W 128
#define FB_H 160
#define MODEL_SIZE 320

// Target classes: cup=41, skateboard=37, mouse=64
const int TARGET_CLASSES[] = {37, 41, 64};
const int NUM_TARGET_CLASSES = 3;

// Yellow color in RGB565
#define COLOR_YELLOW 0xFFE0

struct Detection {
    float x, y, w, h;
    float confidence;
    int class_id;
};

// Fast YUYV to RGB565 conversion
static inline uint16_t yuyv_to_rgb565(uint8_t y, int u, int v)
{
    int r = y + ((351 * v) >> 8);
    int g = y - ((179 * v + 86 * u) >> 8);
    int b = y + ((443 * u) >> 8);
    
    r = (r < 0) ? 0 : (r > 255) ? 255 : r;
    g = (g < 0) ? 0 : (g > 255) ? 255 : g;
    b = (b < 0) ? 0 : (b > 255) ? 255 : b;
    
    return ((r & 0xF8) << 8) | ((g & 0xFC) << 3) | (b >> 3);
}

// Check if class is target
static inline bool is_target_class(int class_id)
{
    for (int i = 0; i < NUM_TARGET_CLASSES; i++) {
        if (TARGET_CLASSES[i] == class_id)
            return true;
    }
    return false;
}

// Draw horizontal line
static inline void draw_h_line(uint16_t *fb, int x1, int x2, int y, uint16_t color)
{
    if (y < 0 || y >= FB_H) return;
    if (x1 < 0) x1 = 0;
    if (x2 >= FB_W) x2 = FB_W - 1;
    for (int x = x1; x <= x2; x++) {
        fb[y * FB_W + x] = color;
    }
}

// Draw vertical line
static inline void draw_v_line(uint16_t *fb, int x, int y1, int y2, uint16_t color)
{
    if (x < 0 || x >= FB_W) return;
    if (y1 < 0) y1 = 0;
    if (y2 >= FB_H) y2 = FB_H - 1;
    for (int y = y1; y <= y2; y++) {
        fb[y * FB_W + x] = color;
    }
}

// Draw thick bounding box (2 pixels wide)
void draw_bbox(uint16_t *fb, int x1, int y1, int x2, int y2, uint16_t color)
{
    // Top and bottom (2 pixels thick)
    draw_h_line(fb, x1, x2, y1, color);
    draw_h_line(fb, x1, x2, y1+1, color);
    draw_h_line(fb, x1, x2, y2, color);
    draw_h_line(fb, x1, x2, y2-1, color);
    
    // Left and right (2 pixels thick)
    draw_v_line(fb, x1, y1, y2, color);
    draw_v_line(fb, x1+1, y1, y2, color);
    draw_v_line(fb, x2, y1, y2, color);
    draw_v_line(fb, x2-1, y1, y2, color);
}

int main()
{
    // Open camera
    int cam = open("/dev/video0", O_RDWR);
    if (cam < 0) { perror("open video0"); return 1; }
    
    struct v4l2_format fmt = {0};
    fmt.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    fmt.fmt.pix.width  = CAM_W;
    fmt.fmt.pix.height = CAM_H;
    fmt.fmt.pix.pixelformat = V4L2_PIX_FMT_YUYV;
    fmt.fmt.pix.field = V4L2_FIELD_NONE;
    
    if (ioctl(cam, VIDIOC_S_FMT, &fmt) < 0) {
        perror("VIDIOC_S_FMT");
        return 1;
    }
    
    struct v4l2_requestbuffers req = {0};
    req.count = 1;
    req.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    req.memory = V4L2_MEMORY_MMAP;
    
    if (ioctl(cam, VIDIOC_REQBUFS, &req) < 0) {
        perror("REQBUFS");
        return 1;
    }
    
    struct v4l2_buffer buf = {0};
    buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    buf.memory = V4L2_MEMORY_MMAP;
    buf.index = 0;
    
    if (ioctl(cam, VIDIOC_QUERYBUF, &buf) < 0) {
        perror("QUERYBUF");
        return 1;
    }
    
    void *map = mmap(NULL, buf.length, PROT_READ | PROT_WRITE,
                     MAP_SHARED, cam, buf.m.offset);
    if (map == MAP_FAILED) {
        perror("mmap");
        return 1;
    }
    
    // Open framebuffer
    int fb = open("/dev/fb0", O_RDWR);
    if (fb < 0) { perror("open fb0"); return 1; }
    
    // Load YOLO-Fastest model
    ncnn::Net yolo;
    yolo.opt.use_vulkan_compute = false;
    yolo.opt.num_threads = 2;  // BeagleBone has 1 core, but 2 threads helps with NEON
    
    printf("Loading YOLO-Fastest-1.1 model...\n");
    if (yolo.load_param("/home/beagle/Yolo-Fastest/sample/ncnn/model/yolo-fastest-1.1.param")) {
        fprintf(stderr, "Failed to load param\n");
        return 1;
    }
    if (yolo.load_model("/home/beagle/Yolo-Fastest/sample/ncnn/model/yolo-fastest-1.1.bin")) {
        fprintf(stderr, "Failed to load model\n");
        return 1;
    }
    
    // Start streaming
    if (ioctl(cam, VIDIOC_STREAMON, &buf.type) < 0) {
        perror("STREAMON");
        return 1;
    }
    
    printf("Streaming with YOLO-Fastest detection (NEON enabled)...\n");
    printf("Detecting: cup, skateboard, mouse\n");
    
    uint16_t fb_pixels[FB_W * FB_H];
    std::vector<Detection> detections;
    
    const int scale_x = (CAM_H << 16) / FB_W;
    const int scale_y = (CAM_W << 16) / FB_H;
    
    int frame_count = 0;
    
    while (1)
    {
        if (ioctl(cam, VIDIOC_QBUF, &buf) < 0) {
            perror("QBUF"); 
            return 1;
        }
        
        if (ioctl(cam, VIDIOC_DQBUF, &buf) < 0) {
            perror("DQBUF"); 
            return 1;
        }
        
        uint8_t *yuyv = (uint8_t*)map;
        
        // Convert camera to framebuffer with rotation
        memset(fb_pixels, 0, sizeof(fb_pixels));
        
        for (int fb_y = 0; fb_y < FB_H; fb_y++) {
            for (int fb_x = 0; fb_x < FB_W; fb_x++) {
                int cam_x = (fb_y * scale_y) >> 16;
                int cam_y = CAM_H - 1 - ((fb_x * scale_x) >> 16);
                
                if (cam_x >= CAM_W || cam_y < 0 || cam_y >= CAM_H)
                    continue;
                
                int cam_x_even = cam_x & ~1;
                int yuyv_idx = (cam_y * CAM_W + cam_x_even) * 2;
                
                uint8_t y_val = yuyv[yuyv_idx + (cam_x & 1) * 2];
                int u = (int)yuyv[yuyv_idx + 1] - 128;
                int v = (int)yuyv[yuyv_idx + 3] - 128;
                
                fb_pixels[fb_y * FB_W + fb_x] = yuyv_to_rgb565(y_val, u, v);
            }
        }
        
        // Run detection every 3 frames for better FPS
        if (frame_count % 3 == 0) {
            detections.clear();
            
            // Prepare NCNN input (320x320 RGB)
            // Convert YUYV to RGB buffer first for NCNN
            unsigned char* rgb_data = new unsigned char[CAM_W * CAM_H * 3];
            for (int y = 0; y < CAM_H; y++) {
                for (int x = 0; x < CAM_W; x += 2) {
                    int idx = (y * CAM_W + x) * 2;
                    uint8_t y1 = yuyv[idx];
                    int u = (int)yuyv[idx+1] - 128;
                    uint8_t y2 = yuyv[idx+2];
                    int v = (int)yuyv[idx+3] - 128;
                    
                    // Pixel 1
                    int r1 = y1 + ((351 * v) >> 8);
                    int g1 = y1 - ((179 * v + 86 * u) >> 8);
                    int b1 = y1 + ((443 * u) >> 8);
                    r1 = (r1 < 0) ? 0 : (r1 > 255) ? 255 : r1;
                    g1 = (g1 < 0) ? 0 : (g1 > 255) ? 255 : g1;
                    b1 = (b1 < 0) ? 0 : (b1 > 255) ? 255 : b1;
                    
                    int rgb_idx1 = (y * CAM_W + x) * 3;
                    rgb_data[rgb_idx1] = r1;
                    rgb_data[rgb_idx1 + 1] = g1;
                    rgb_data[rgb_idx1 + 2] = b1;
                    
                    // Pixel 2
                    int r2 = y2 + ((351 * v) >> 8);
                    int g2 = y2 - ((179 * v + 86 * u) >> 8);
                    int b2 = y2 + ((443 * u) >> 8);
                    r2 = (r2 < 0) ? 0 : (r2 > 255) ? 255 : r2;
                    g2 = (g2 < 0) ? 0 : (g2 > 255) ? 255 : g2;
                    b2 = (b2 < 0) ? 0 : (b2 > 255) ? 255 : b2;
                    
                    int rgb_idx2 = (y * CAM_W + x + 1) * 3;
                    rgb_data[rgb_idx2] = r2;
                    rgb_data[rgb_idx2 + 1] = g2;
                    rgb_data[rgb_idx2 + 2] = b2;
                }
            }
            
            ncnn::Mat in = ncnn::Mat::from_pixels_resize(
                rgb_data, ncnn::Mat::PIXEL_RGB, CAM_W, CAM_H, MODEL_SIZE, MODEL_SIZE);
            
            delete[] rgb_data;
            
            const float mean_vals[3] = {0.f, 0.f, 0.f};
            const float norm_vals[3] = {1/255.f, 1/255.f, 1/255.f};
            in.substract_mean_normalize(mean_vals, norm_vals);
            
            // Run inference
            ncnn::Extractor ex = yolo.create_extractor();
            ex.input("data", in);
            
            ncnn::Mat out;
            ex.extract("output", out);
            
            // Parse detections (YOLO format: x, y, w, h, conf, class_scores...)
            for (int i = 0; i < out.h; i++) {
                const float* values = out.row(i);
                
                float confidence = values[4];
                if (confidence < 0.5f) continue;
                
                // Find class with max score
                int class_id = 0;
                float max_class_score = values[5];
                for (int j = 1; j < 80; j++) {
                    if (values[5 + j] > max_class_score) {
                        max_class_score = values[5 + j];
                        class_id = j;
                    }
                }
                
                float final_conf = confidence * max_class_score;
                if (final_conf < 0.5f) continue;
                
                // Only keep target classes
                if (!is_target_class(class_id)) continue;
                
                Detection det;
                det.x = values[0];
                det.y = values[1];
                det.w = values[2];
                det.h = values[3];
                det.confidence = final_conf;
                det.class_id = class_id;
                detections.push_back(det);
            }
            
            if (!detections.empty()) {
                printf("Frame %d: Found %zu detections\n", frame_count, detections.size());
            }
        }
        
        // Draw bounding boxes (transform from camera space to FB space with rotation)
        for (const auto& det : detections) {
            // Detection coords are normalized to MODEL_SIZE (320x320)
            // Map to camera space first
            float cam_x = det.x * CAM_W / MODEL_SIZE;
            float cam_y = det.y * CAM_H / MODEL_SIZE;
            float cam_w = det.w * CAM_W / MODEL_SIZE;
            float cam_h = det.h * CAM_H / MODEL_SIZE;
            
            // Transform to framebuffer space with 90Â° rotation
            // Camera(x,y) -> FB(y, HEIGHT-1-x) after scaling
            int fb_x1 = (int)((cam_y - cam_h/2) * FB_W / CAM_H);
            int fb_x2 = (int)((cam_y + cam_h/2) * FB_W / CAM_H);
            int fb_y1 = (int)((cam_x - cam_w/2) * FB_H / CAM_W);
            int fb_y2 = (int)((cam_x + cam_w/2) * FB_H / CAM_W);
            
            // Clamp to screen bounds
            if (fb_x1 < 0) fb_x1 = 0;
            if (fb_x2 >= FB_W) fb_x2 = FB_W - 1;
            if (fb_y1 < 0) fb_y1 = 0;
            if (fb_y2 >= FB_H) fb_y2 = FB_H - 1;
            
            draw_bbox(fb_pixels, fb_x1, fb_y1, fb_x2, fb_y2, COLOR_YELLOW);
        }
        
        // Write to framebuffer
        lseek(fb, 0, SEEK_SET);
        write(fb, fb_pixels, sizeof(fb_pixels));
        
        frame_count++;
    }
    
    munmap(map, buf.length);
    close(cam);
    close(fb);
    
    return 0;
}
